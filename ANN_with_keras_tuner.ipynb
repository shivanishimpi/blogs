{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN-with-keras-tuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanishimpi/blogs/blob/main/ANN_with_keras_tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQVxtaoIFBDa"
      },
      "source": [
        "> This notebook was created to demonstrate ANN with keras-tuner as an extension to the [keras-tuner blog](https://shivanishimpi9.medium.com/choosing-the-right-set-of-hyperparameters-keras-tuner-introduction-implementation-d4c387f4d655?postPublishedType=repub) \n",
        "\n",
        "To follow through the notebook explanation, join our YouTube [live session](https://www.youtube.com/watch?v=DQuS_cZg2wI)\n",
        "\n",
        "Download the Churn_Modelling.csv file [here](https://drive.google.com/file/d/1ZC5IJ4DiRAFMoIX7t9JyU84IF8lUxa0q/view?usp=sharing)\n",
        "\n",
        "\n",
        "Date Created: January 15, 2021\n",
        "\n",
        "\n",
        "\n",
        "**Authors:**\n",
        "\n",
        "1. Satyajit Pattnaik `ANN`\n",
        "2. Shivani Shimpi `Keras-tuner`\n",
        "\n",
        "Reach us out on GitHub / LinkedIn\n",
        "- shivanishimpi9@gmail.com [[GitHub](https://github.com/shivanishimpi)] [[LinkedIn](https://www.linkedin.com/in/shivani-shimpi-5113a8170/)]\n",
        "- pattnaiksatyajit89@gmail.com [[LinkedIn](https://www.linkedin.com/in/satyajit-pattnaik-b41392102/)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "psOd0uk6CDig",
        "outputId": "4bedb821-0059-48de-b9f5-77cb5e38f497"
      },
      "source": [
        "#@title Mount Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7DDRawdCcUU",
        "outputId": "f3f21cca-354e-4aa2-d661-e0c70e32ccbb"
      },
      "source": [
        "cd '/content/drive/MyDrive/Blogs/Keras-tuner' #set as per your needs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Blogs/Keras-tuner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8XjHm_-_U4b",
        "outputId": "626a1886-6267-468f-e41c-1aea1ae15f07"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values\n",
        "\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 0 0 ... 1 1 101348.88]\n",
            " [608 2 0 ... 0 1 112542.58]\n",
            " [502 0 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 0 0 ... 0 1 42085.58]\n",
            " [772 1 1 ... 1 0 92888.52]\n",
            " [792 0 0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spI4ppTB_FV6"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mai6Gk6REihe",
        "outputId": "fc494c1b-7b01-4ad4-da66-218ccc1e9a67"
      },
      "source": [
        "#Classical ML\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1350  245]\n",
            " [ 185  220]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyTSyzO-Ep7V",
        "outputId": "d4703fb1-9aed-4dae-b7eb-dd26b63b76df"
      },
      "source": [
        "# Now let's make the ANN!\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the third  hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "y_train[0]\n",
        "# Fitting the ANN to the Training set\n",
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 25)\n",
        "\n",
        "# Part 3 - Making predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5861 - accuracy: 0.7968\n",
            "Epoch 2/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4282 - accuracy: 0.8033\n",
            "Epoch 3/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4121 - accuracy: 0.8208\n",
            "Epoch 4/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4063 - accuracy: 0.8232\n",
            "Epoch 5/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4020 - accuracy: 0.8216\n",
            "Epoch 6/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3893 - accuracy: 0.8321\n",
            "Epoch 7/25\n",
            "800/800 [==============================] - 1s 999us/step - loss: 0.3716 - accuracy: 0.8487\n",
            "Epoch 8/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3797 - accuracy: 0.8446\n",
            "Epoch 9/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3659 - accuracy: 0.8521\n",
            "Epoch 10/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3661 - accuracy: 0.8512\n",
            "Epoch 11/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3660 - accuracy: 0.8528\n",
            "Epoch 12/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3649 - accuracy: 0.8481\n",
            "Epoch 13/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3605 - accuracy: 0.8524\n",
            "Epoch 14/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3556 - accuracy: 0.8528\n",
            "Epoch 15/25\n",
            "800/800 [==============================] - 1s 990us/step - loss: 0.3550 - accuracy: 0.8571\n",
            "Epoch 16/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3591 - accuracy: 0.8487\n",
            "Epoch 17/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3441 - accuracy: 0.8605\n",
            "Epoch 18/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3458 - accuracy: 0.8594\n",
            "Epoch 19/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3545 - accuracy: 0.8558\n",
            "Epoch 20/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3539 - accuracy: 0.8580\n",
            "Epoch 21/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8462\n",
            "Epoch 22/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8532\n",
            "Epoch 23/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3583 - accuracy: 0.8526\n",
            "Epoch 24/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3483 - accuracy: 0.8542\n",
            "Epoch 25/25\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3518 - accuracy: 0.8559\n",
            "[[1529   66]\n",
            " [ 226  179]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzj3uD34JXPY"
      },
      "source": [
        "# Predicting a single new observation\n",
        "\"\"\"\n",
        "Predict if the customer with the following informations will leave the bank:\n",
        "Geography: France\n",
        "Credit Score: 600\n",
        "Gender: Male\n",
        "Age: 40\n",
        "Tenure: 3\n",
        "Balance: 60000\n",
        "Number of Products: 2\n",
        "Has Credit Card: Yes\n",
        "Is Active Member: Yes\n",
        "Estimated Salary: 50000\n",
        "\"\"\"\n",
        "new_prediction = classifier.predict(sc.transform(np.array([[600, 0, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
        "new_prediction = (new_prediction > 0.5)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "#Importing few libraries for k-folds\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "def build_classifier():\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 1)\n",
        "\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv =10, n_jobs = -1 )\n",
        "mean1 = accuracies.mean()\n",
        "variance = accuracies.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBJJXuSrDA_b",
        "outputId": "d6df5f7d-84e7-4242-fa1c-9acad6933d67"
      },
      "source": [
        "#Improvising the ANN - Hyper parameter optimization\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def build_classifier():\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10)) \n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "\n",
        "parameters = {'batch_size': [10,15],\n",
        "              'epochs': [1,5]}\n",
        "\n",
        "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', n_jobs = -1, cv = 10)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_\n",
        "grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 974us/step - loss: 0.5667 - accuracy: 0.8010\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4358 - accuracy: 0.7956\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4345 - accuracy: 0.7968\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4170 - accuracy: 0.8287\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4162 - accuracy: 0.8313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.827875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Ot6QBXDGCf"
      },
      "source": [
        "## Keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrnmjW6SOoUA"
      },
      "source": [
        "We are going to begin by setting up the virtual environment for `keras-tuner` by installing the library.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcIBJpFTOxPi",
        "outputId": "be89e0e3-1352-406b-d3fb-11455fd5cb5e"
      },
      "source": [
        "!pip install -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras-tuner in /usr/local/lib/python3.6/dist-packages (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (20.8)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S5aRzpjYlDJ"
      },
      "source": [
        "Now that we have that downloaded, let's import all the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Iy2rbZMYj0D"
      },
      "source": [
        "import kerastuner\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "LOG_DIR = f\"{int(time.time())}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu4u3KvNYwqE"
      },
      "source": [
        "Creating a hypermodel with `keras-tuner`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi6ZTZJYaN4s"
      },
      "source": [
        "I'm going to rename the classifier in the code above to model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqvueniKDFM9"
      },
      "source": [
        "def build_model(hp):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(Dense(units = hp.Int('inputUnits', min_value=6, max_value=12), kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
        "    \n",
        "    for i in range(hp.Int(\"numLayers\", min_value=1, max_value=4)):\n",
        "      model.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    \n",
        "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    \n",
        "    model.compile(\n",
        "      optimizer = tf.keras.optimizers.Adam(hp.Choice('learnRate', [0.01,0.001,0.02,0.001])),\n",
        "      loss = 'binary_crossentropy',\n",
        "      metrics = ['acc']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6bmjDFrR921"
      },
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_acc',\n",
        "    max_trials = 5,\n",
        "    executions_per_trial = 3,\n",
        "    directory = LOG_DIR\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3pDOMxdS9bo",
        "outputId": "b0f2c323-69b0-43d1-c522-ab74455d1026"
      },
      "source": [
        "tuner.search(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    epochs = 10,\n",
        "    validation_data = (X_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 15s]\n",
            "val_acc: 0.8575000166893005\n",
            "\n",
            "Best val_acc So Far: 0.8575000166893005\n",
            "Total elapsed time: 00h 01m 16s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGLMvJNuY9rA",
        "outputId": "b4eb43cd-e12e-4c09-c626-5308938b8cf8"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in 1610802763/untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_acc', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "inputUnits: 11\n",
            "numLayers: 2\n",
            "learnRate: 0.02\n",
            "Score: 0.8580000003178915\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "inputUnits: 9\n",
            "numLayers: 4\n",
            "learnRate: 0.01\n",
            "Score: 0.8501666784286499\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "inputUnits: 10\n",
            "numLayers: 1\n",
            "learnRate: 0.01\n",
            "Score: 0.8423333366711935\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "inputUnits: 9\n",
            "numLayers: 4\n",
            "learnRate: 0.001\n",
            "Score: 0.8399999936421713\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "inputUnits: 12\n",
            "numLayers: 1\n",
            "learnRate: 0.001\n",
            "Score: 0.8399999936421713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNz2Ht37UHbh",
        "outputId": "72735140-ffd7-4984-86e4-a0112cd3cc9b"
      },
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inputUnits': 11, 'learnRate': 0.02, 'numLayers': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iivW8GJXVWNq",
        "outputId": "049bb703-93bf-4716-f6ea-461640deac49"
      },
      "source": [
        "tuner.get_best_models()[0].summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 11)                121       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 242\n",
            "Trainable params: 242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InvQL0psZVIB"
      },
      "source": [
        "Saving the best model we have got so far "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAb0mKfUY4ej"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(f'tuner_{int(time.time())}.pkl', 'wb') as f:\n",
        "    pickle.dump(tuner, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k033jx4MaH3U",
        "outputId": "096f68a8-1980-4d3e-c170-ae5f920c3372"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1610751939  1610802763\tANN-with-keras-tuner.ipynb  tuner_1610802841.pkl\n",
            "1610751997  ann.py\tChurn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktsFta39aBVS"
      },
      "source": [
        "tmp_tuner = pickle.load(open('tuner_1610802841.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBOIZBp4aOvE",
        "outputId": "2667da31-d570-47bd-f673-ac593f94966d"
      },
      "source": [
        "tmp_tuner.get_best_models()[0].summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 11)                121       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 242\n",
            "Trainable params: 242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObwZ54s7bBCX"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ6gubBFa-3j"
      },
      "source": [
        "That's the end of this tutorial implmenting ANN from scratch and modifying your code by using keras-tuner.\n",
        "If you liked it and learned something new, let us know. And if there are any more topics you'd like us to cover, do reach out to us regarding that as well.\n",
        "\n",
        "Have an amazing time ahead."
      ]
    }
  ]
}